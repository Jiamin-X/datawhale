"1.spark 和 mapreduce有哪些区别?\n",
    "MapReduce计算模型延迟过高，无法胜任实时、快速计算的需求，因而只适用于离线批处理的应用场景。\n",
    "目前的MapReduce框架都是把中间结果写入到HDFS中，带来了大量的数据复制、磁盘IO和序列化开销。\n",
    "\n",
    "Spark的计算模式也属于MapReduce，但不局限于Map和Reduce操作，还提供了多种数据集操作类型，编程模型比MapReduce更灵活；\n",
    "Spark提供了内存计算，中间结果直接放到内存中，带来了更高的迭代运算效率；\n",
    "Spark基于DAG的任务调度执行机制，要优于MapReduce的迭代执行机制。\n",
    "\n",
    "2.RDD的本质是什么?\n",
    "一个RDD就是一个分布式对象集合，本质上是一个只读的分区记录集合，每个RDD可以分成多个分区，每个分区就是一个数据集片段，并且一个RDD的不同分区可以被保存到集群中不同的节点上，从而可以在集群中的不同节点上进行并行计算。"
   
